{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify Note Texts using GPT-4o\n",
    "\n",
    "**Goal of this notebook:**  \n",
    "Use AI to extract ONLY the important components of the Mimic-III NOTEEVENT TEXT field. Removing details such as admission dates and medical dosages will reduce the token count, and simplify the text _while_ keeping relevant context and the original sentences that would be lost if we were to use a parser such as [mednlp](https://github.com/plandes/mednlp) python package.\n",
    "\n",
    "The extracted data will be used to...  \n",
    "- Simplify the note text before attempting to code. This will improve calssification results\n",
    "\n",
    "**Requirements**  \n",
    "- Setup Azure Open AI Resource with GPT-4o deployment, ensure [.env](./.env.sample) file is populated up to date\n",
    "- Setup Azure Language Resource in the same manor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from textwrap import dedent\n",
    "from fuzzywuzzy import process\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.textanalytics import TextAnalyticsClient, ExtractiveSummaryAction\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import tiktoken\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get medical coding data, take a small subsample\n",
    "\n",
    "df = pd.read_csv(\"data/joined/dataset_single_notes_full.csv.gz\").sample(1, replace=False,random_state=1234)\n",
    "print(df.shape)\n",
    "display(df.dtypes)\n",
    "display(df.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper Functions\n",
    "\n",
    "# Function to get token counts\n",
    "def get_token_counts(text):\n",
    "    encoding = tiktoken.get_encoding('cl100k_base')\n",
    "    num_tokens = len(encoding.encode(text))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use AOAI to Simplify Note Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_BASE\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=\"2024-02-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton to build prompt\n",
    "\n",
    "def build_prompt(note):\n",
    "    sys = \"\"\"\n",
    "    Parse the following medical note. Return any sentences that relates to a diagnosis. Ignore other information such as patient name, dates, medicine types, dosage amounts, prior medical history, and prior treamtment.\n",
    "    DO NOT ADD ANY INFORMATION TO THE NOTE. ONLY RETURN THE RELEVANT SENTENCES. \n",
    "    \"\"\"\n",
    "    prompt = f\"{note}\"\n",
    "\n",
    "    return (sys, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aoai_extract(note):\n",
    "    sys, prompt = build_prompt(note)\n",
    "    response = aoai_client.chat.completions.create(\n",
    "        model=os.getenv(\"AOAI_MAIN_DEPLOYMENT_NAME\"), # model = \"deployment_name\".\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": dedent(sys)},\n",
    "            {\"role\": \"user\", \"content\": dedent(prompt)}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df[\"AOAI_EX\"] = df[\"TEXT\"].progress_apply(lambda x: aoai_extract(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text analysis - Is any information lost?\n",
    "sub_df=df[['ICD9_CODE','TEXT','AOAI_EX']]\n",
    "display(sub_df.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Detect hallucinations - ensure that only sentences from the original notes are returned\n",
    "\n",
    "def validate_subset(original, extracted):\n",
    "    original = original.replace('[','').replace(']','').replace('*','').replace('\\n',' ').strip()\n",
    "    extracted = extracted.replace('[','').replace(']','').replace('*','').replace('\\n',' ').strip()\n",
    "    extracted_list = list(filter(None,extracted.split('.')))\n",
    "    true_list = []\n",
    "    falses = 0\n",
    "    \n",
    "    for sentence in extracted_list:\n",
    "        fuzzy_match = process.extractOne(sentence, original.split('.'))\n",
    "        # print(fuzzy_match)\n",
    "        if fuzzy_match[1] > 85: # Tune this threshold accordingly\n",
    "            true_list.append(sentence)\n",
    "        else:\n",
    "            falses = falses+1\n",
    "            #print(f\"False: {sentence}\")\n",
    "\n",
    "    return (falses, \". \".join(true_list))\n",
    "\n",
    "#Test\n",
    "result = validate_subset(sub_df['TEXT'].iloc[0], sub_df['AOAI_EX'].iloc[0])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df[\"AOAI_EX_CLEAN\"] = df.progress_apply(lambda x: validate_subset(x['TEXT'], x['AOAI_EX']), axis=1)\n",
    "df[\"AOAI_MISMATCH\"] = df[\"AOAI_EX_CLEAN\"].apply(lambda x: x[0])\n",
    "df[\"AOAI_EX_CLEAN\"] = df[\"AOAI_EX_CLEAN\"].apply(lambda x: x[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[[\"ICD9_CODE\",\"TEXT\",\"AOAI_EX_CLEAN\",\"AOAI_MISMATCH\"]].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg token count difference - How much efficiency is gained?\n",
    "df[\"AOAI_TOKENS\"] = df[\"AOAI_EX_CLEAN\"].apply(lambda x: get_token_counts(x))\n",
    "df[\"TEXT_TOKENS\"] = df[\"TEXT\"].apply(lambda x: get_token_counts(x))\n",
    "\n",
    "print(f\"Average Original Text tokens: {df['TEXT_TOKENS'].mean()}\")\n",
    "print(f\"Average AOAI Extracted tokens: {df['AOAI_TOKENS'].mean()}\")\n",
    "print(f\"Average token count difference: {(df['TEXT_TOKENS'] - df['AOAI_TOKENS']).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Azure AI Language _Extractive_ Summarization to Simplify Note Text\n",
    "\n",
    "In some cases, in the intrest of extreme risk aversion using a GPT based LLM approach may not be acceptable. One alternative is the AI Language service. This implementation uses **extractive** summaries to simplify the note text. Unlike **abstractive** summaries, **extractive** summaries only use text from the original corpus and do not alter that text, or create next text in any way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate the client using your key and endpoint \n",
    "key = os.getenv(\"LANGUAGE_KEY\")\n",
    "endpoint = os.getenv(\"LANGUAGE_ENDPOINT\")\n",
    "\n",
    "client = TextAnalyticsClient(\n",
    "        endpoint=endpoint, \n",
    "        credential=AzureKeyCredential(key)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary(client, text):\n",
    "\n",
    "    poller = client.begin_analyze_actions(\n",
    "        [text],\n",
    "        actions=[\n",
    "            ExtractiveSummaryAction(max_sentence_count=20, # Note: Tune this based on output results\n",
    "                                    order_by=\"Offset\",\n",
    "                                    disable_service_logs=True,\n",
    "                                    model_version=\"latest\"),\n",
    "        ],\n",
    "    )\n",
    "    extract_summary_results = poller.result()\n",
    "    for result in extract_summary_results:\n",
    "        extract_summary_result = result[0]\n",
    "        if extract_summary_result.is_error:\n",
    "            print(\"...Is an error with code '{}' and message '{}'\".format(\n",
    "                result.error.code, result.error.message\n",
    "            ))\n",
    "            return None\n",
    "        else:\n",
    "            # print(\"Summary extracted.\")\n",
    "            return \" \".join([sentence.text for sentence in extract_summary_result.sentences])\n",
    "    \n",
    "        \n",
    "# Test\n",
    "text = df['TEXT'].iloc[0]\n",
    "summary = extract_summary(client, text)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df[\"AZ_LANG_EX\"] = df[\"TEXT\"].progress_apply(lambda x: extract_summary(client,x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AZ_LANG_TOKENS\"] = df[\"AZ_LANG_EX\"].apply(lambda x: get_token_counts(x))\n",
    "df[\"TEXT_TOKENS\"] = df[\"TEXT\"].apply(lambda x: get_token_counts(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Examine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text analysis - Is any information lost?\n",
    "sub_df=df[['ICD9_CODE','TEXT','AZ_LANG_EX']]\n",
    "display(sub_df.iloc[[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg token count difference - How much efficiency is gained?\n",
    "print(f\"Average Original Text tokens: {df['TEXT_TOKENS'].mean()}\")\n",
    "print(f\"Average AOAI Extracted tokens: {df['AZ_LANG_TOKENS'].mean()}\")\n",
    "print(f\"Average token count difference: {(df['TEXT_TOKENS'] - df['AZ_LANG_TOKENS']).mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The Azure Language Extract is not a great fit for medical coding use cases. The summary does not highly rank symptom and diagnosis information, instead focusing on the human behavior and processes of the note.\n",
    "\n",
    "2. The LLM based extract can be prompt engineered to grab imformation that is much more relevant to medical coding. However, it takes additional work to ensure that the LLM does not hallucinate additional information. A rudimentary approach is demonstrated in this notebook, but further engineering may be required for a production system. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
