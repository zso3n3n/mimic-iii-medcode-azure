{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplify Note Texts using GPT-4o\n",
    "\n",
    "**Goal of this notebook:**  \n",
    "Use AI to extract ONLY the important components of the Mimic-III NOTEEVENT TEXT field. Removing details such as admission dates and medical dosages will reduce the token count, and simplify the text _while_ keeping relevant context and the original sentences that would be lost if we were to use a parser such as [Azure Text Analytics for Health](./01_az_text_analytics.ipynb) or the [mednlp](https://github.com/plandes/mednlp) python package.\n",
    "\n",
    "The extracted data will be used to...  \n",
    "- Simplify the note text before attempting to code. This will improve calssification results\n",
    "\n",
    "**Requirements**  \n",
    "- Setup Azure Open AI Resource with GPT-4o deployment, ensure [.env](./.env.sample) file is populated up to date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from textwrap import dedent\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import tiktoken\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get medical coding data, take a small subsample\n",
    "\n",
    "df = pd.read_csv(\"data/joined/dataset_single_notes_full.csv.gz\").sample(5, replace=False,random_state=1234)\n",
    "print(df.shape)\n",
    "display(df.dtypes)\n",
    "display(df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use AOAI to Simplify Note Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_BASE\"), \n",
    "    api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "    api_version=\"2024-02-01\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get token counts\n",
    "\n",
    "def get_token_counts(text):\n",
    "    encoding = tiktoken.get_encoding('cl100k_base')\n",
    "    num_tokens = len(encoding.encode(text))\n",
    "    return num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciton to build prompt\n",
    "\n",
    "def build_prompt(note):\n",
    "    sys = \"\"\"\n",
    "    Parse the following medical note. Return any sentences that relates to a diagnosis. Ignore other information such as patient name, dates, medicine types, dosage amounts, prior medical history, prior treamtment, etc.\n",
    "    DO NOT ADD ANY INFORMATION TO THE NOTE. ONLY RETURN THE RELEVANT SENTENCES. \n",
    "    \"\"\"\n",
    "    prompt = f\"{note}\"\n",
    "\n",
    "    return (sys, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aoai_extract(note):\n",
    "    sys, prompt = build_prompt(note)\n",
    "    response = aoai_client.chat.completions.create(\n",
    "        model=os.getenv(\"AOAI_MAIN_DEPLOYMENT_NAME\"), # model = \"deployment_name\".\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": dedent(sys)},\n",
    "            {\"role\": \"user\", \"content\": dedent(prompt)}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AOAI_EX\"] = df[\"TEXT\"].apply(lambda x: aoai_extract(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"AOAI_TOKENS\"] = df[\"AOAI_EX\"].apply(lambda x: get_token_counts(x))\n",
    "df[\"TEXT_TOKENS\"] = df[\"TEXT\"].apply(lambda x: get_token_counts(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg token count difference - How much efficiency is gained?\n",
    "print(f\"Average Original Text tokens: {df['TEXT_TOKENS'].mean()}\")\n",
    "print(f\"Average AOAI Extracted tokens: {df['AOAI_TOKENS'].mean()}\")\n",
    "print(f\"Average token count difference: {(df['TEXT_TOKENS'] - df['AOAI_TOKENS']).mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text analysis - Is any information lost?\n",
    "sub_df=df[['ICD9_CODE','TEXT','AOAI_EX']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 0\n",
    "display(sub_df.iloc[[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Detailed Analysis (TODO)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
