{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heirarchical Coding with Small Language Models  \n",
    "  \n",
    "**Goal of this notebook**  \n",
    "- Mitigate the challenge of having a vast label space by breaking down the potential classes only to specific targets. In some cases, this would reduce the label space from 1000s of codes to fewer than 20.\n",
    "\n",
    "**Methodology** \n",
    "   \n",
    "The approach is the leverage small language model(s) to traverse a heirarchy tree of ICD-9 codes and ask many small, simple, questions to classify a Note Event from the MIMI-III dataset.\n",
    "\n",
    "For example, the image below is a representation of a small portion of the ICD9 code tree. The branch in the picture below shows a subset of the 'Infectious and Parasitic Disease' Chapter of the ICD9 code tree. [View a full json representation of the taxonomy here.](./icd9_full.json) For this implementation, ICD-9 Code levels are broken down into Chapters, Blocks, Categories. To expand on this implementation the Tree can be broken down further into Sub-categories, Extension I, and Extension II codes.\n",
    "  \n",
    "The coding algorithm recursively walks the tree, starting at the top level and continuing down any branch(es) directed by the mini model until the final codes are returned. \n",
    "\n",
    "Sample subset (condensed Chapter 0 branch) of the ICD9 code tree: \n",
    "```\n",
    "0        Infectious and Parasitic Diseases  \n",
    "├── 00   Intestinal infectious diseases  \n",
    "│   ├── 001 Cholera  \n",
    "│   ├── 002 Typhoid and paratyphoid fevers  \n",
    "│   ├── 003 Salmonella  \n",
    "│   ├── 004 Shigellosis  \n",
    "│   ├── 005 Other poisoning (bacterial)  \n",
    "│   ├── 006 Amebiasis  \n",
    "│   ├── 007 Other protozoal intestinal diseases  \n",
    "│   ├── 008 Intestinal infections due to other organisms  \n",
    "│   └── 009 Ill-defined intestinal infections  \n",
    "...  \n",
    "├── 09   Rickettsioses and other arthropod-borne diseases  \n",
    "│   ├── ...   \n",
    "│   ├── 087 Relapsing fever  \n",
    "│   └── 088 Other arthropod-borne diseases\n",
    "\n",
    "```\n",
    "\n",
    "**Further Reading**  \n",
    "  \n",
    "This approach is explored further in this paper:  \n",
    " [Automated clinical coding using off-the-shelf large language models](https://arxiv.org/pdf/2310.06552) (Boyle et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tree import TaxonomyParser\n",
    "from zensols.mednlp import ApplicationFactory\n",
    "\n",
    "from nltk import flatten\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from textwrap import dedent\n",
    "from openai import AzureOpenAI\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "import functools\n",
    "import logging\n",
    "import os\n",
    "\n",
    "\n",
    "doc_parser = ApplicationFactory.get_doc_parser()\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "print(os.getenv(\"AZURE_OPENAI_BASE\"))\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Code Tree\n",
    "code_tree = TaxonomyParser()\n",
    "code_tree.read_from_json(\"icd9_tax.json\")\n",
    "\n",
    "print(code_tree.find_by_name(\"00\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Tree\n",
    "code_tree.visualize(\"0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note Parsing Functions\n",
    "\n",
    "def format_icd9(x):\n",
    "    new_codes = []\n",
    "    code_list = ast.literal_eval(x)\n",
    "    for code in code_list:\n",
    "        new_codes.append(f\"{code:0>3}\".format(num=\"1\"))\n",
    "\n",
    "    return str(new_codes)\n",
    "\n",
    "def parse_note(note:str) -> str:\n",
    "    \n",
    "    doc = doc_parser(note)\n",
    "\n",
    "    new_note = set([])\n",
    "    for tok in doc.tokens:\n",
    "        if tok.is_concept and tok.tuis_ in ['T184', 'T047', 'T046', 'T033', 'T037','T191','T005', 'T004', 'T007', 'T008']:\n",
    "            \n",
    "            # print(tok, tok.detected_name_, tok.sub_names, tok.pref_name_, tok.tuis_, tok.tui_descs_)\n",
    "            new_note.add(tok.detected_name_.replace(\"~\",\" \"))\n",
    "            new_note.add(tok.pref_name_.lower())\n",
    "\n",
    "    logger.info(f\"Note Parsing Complete.\")\n",
    "    \n",
    "    return \" \".join(new_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scoring Functions\n",
    "\n",
    "def recall_score(truth, generated):\n",
    "    actual_list = ast.literal_eval(truth)\n",
    "    generated_list = ast.literal_eval(generated)\n",
    "\n",
    "    similar = len(set(actual_list) & set(generated_list))\n",
    "\n",
    "    return similar / len(actual_list)\n",
    "\n",
    "def precision_score(truth, generated):\n",
    "    actual_list = ast.literal_eval(truth)\n",
    "    generated_list = ast.literal_eval(generated)\n",
    "\n",
    "    if len(generated_list) == 0:\n",
    "        return 0\n",
    "\n",
    "    similar = len(set(actual_list) & set(generated_list))\n",
    "\n",
    "    return similar / len(generated_list)\n",
    "\n",
    "def f1_score(truth, generated):\n",
    "    precision = precision_score(truth, generated)\n",
    "    recall = recall_score(truth, generated)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 2 * (precision * recall) / (precision + recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Call to AOAI\n",
    "\n",
    "def call_aoai(sys:str, prompt:str) -> List:\n",
    "\n",
    "    aoai_client = AzureOpenAI(\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_BASE\"), \n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),\n",
    "        api_version=\"2024-02-01\"\n",
    "    )\n",
    "    \n",
    "    response = aoai_client.chat.completions.create(\n",
    "        model=os.getenv(\"AZURE_DEPLOYMENT_NAME\"), # model = \"deployment_name\".\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": dedent(sys)},\n",
    "            {\"role\": \"user\", \"content\": dedent(prompt)}\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        output = ast.literal_eval(response.choices[0].message.content)\n",
    "        return output\n",
    "    except Exception as e:\n",
    "        logger.warning(f\"{e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Prompt Dymanically\n",
    "\n",
    "def get_options(tree, parent_code):\n",
    "    children = tree.get_children(parent_code)\n",
    "    options = []\n",
    "    for child in children:\n",
    "        options.append(f\"{child.name}: {child.description}\")\n",
    "    \n",
    "    return '|'.join(options)\n",
    "\n",
    "def build_prompt(tree, parent_code, note, categories):\n",
    "    sys = \"\"\"\n",
    "    You are a medical expert. Your job is to classify notes of an event into one or more categories. ACCURACY is VERY IMPORTANT to your job.\n",
    "    Choose the best option(s) based on the categories offered. ALWAYS return at least one index. ONLY choose from categories listed. \n",
    "    Respond with a list of quoted string indeces of the categories the note belongs to.\n",
    "    Think through your answer. \n",
    "    \n",
    "    ### EXAMPLE ###\n",
    "    Categories = 0: Infectious and Parasitic Diseases | 1: Neoplasms | 2: Endocrine, Nutritional and Metabolic Diseases, and Immunity Disorders\n",
    "    Note = Patient has Tuberculosis and an Immunity Disorder\n",
    "    Answer: ['0','2']\n",
    "    ## END EXAMPLE ##\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Categories = {categories}\n",
    "    Note = {note}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    return sys, prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive Walk of tree and call aoai to get codes\n",
    "\n",
    "def get_codes_for_note(parent_code, tree, note, level=3):\n",
    "    \n",
    "    categories = get_options(tree, parent_code)\n",
    "    sys, prompt = build_prompt(tree, parent_code, note, categories)\n",
    "\n",
    "    codes = call_aoai(sys, prompt)\n",
    "    \n",
    "    logger.info(f\"Parent Code: {parent_code} | Found: {codes}\")\n",
    "    logger.info(f\"Prompt: {prompt}\")\n",
    "\n",
    "    if codes == [] or codes == ['']:\n",
    "        return ['X'*level]\n",
    "    elif all(len(i) == level for i in codes):\n",
    "        return codes\n",
    "    else:\n",
    "        return list(map(functools.partial(get_codes_for_note, tree=tree, note=note, level=level), codes))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = transform_data(\"data/\") # Only re-run if change in preparation logic\n",
    "df = pd.read_csv(\"data/joined/dataset_single_001_088.csv.gz\")\n",
    "print(df.shape)\n",
    "display(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get L1 and L2 codes for grading purposes\n",
    "\n",
    "def get_parent_codes(code_tree, codes):\n",
    "    code_list = ast.literal_eval(codes)\n",
    "    parent_codes = []\n",
    "    for code in code_list:\n",
    "        parent_codes.append(code_tree.find_by_name(code).parent.name)\n",
    "    \n",
    "    parent_codes = list(set(parent_codes))\n",
    "    return str(parent_codes)\n",
    "\n",
    "df['L2_CODES'] = df['ICD9_CODE'].apply(lambda x: get_parent_codes(code_tree, x))\n",
    "df['L1_CODES'] = df['L2_CODES'].apply(lambda x: get_parent_codes(code_tree, x))\n",
    "display(df[['ICD9_CODE', 'L2_CODES', 'L1_CODES']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take Final Subset\n",
    "\n",
    "df = df[0:10]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Parsed Text field\n",
    "tqdm.pandas()\n",
    "df['PARSED_TEXT'] = df['TEXT'].progress_apply(parse_note)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get ICD9 Codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1 - Get Codes from Gpt-4o mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SIMPLE TEST ###\n",
    "\"\"\"\n",
    "res = flatten(get_codes_for_note(\"root\", code_tree, \"Tuberculosis of the bones and joints and HIV\"))\n",
    "print(res)\n",
    "\"\"\"\n",
    "#### END SIMPLE TEST ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "df['Generated'] = \"\"\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # Parse Note\n",
    "    note = ast.literal_eval(row['TEXT'])[0]\n",
    "    print(f\"Note: {note}\")\n",
    "    # Get Codes\n",
    "    result = flatten(get_codes_for_note(\"0\", code_tree, note, level=2)) # Change level here if needed\n",
    "\n",
    "    # Add result to DF\n",
    "    df.at[index, 'Generated'] = str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Results\n",
    "\n",
    "display(df[['ICD9_CODE','L1_CODES','L2_CODES', 'Generated']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grade L2 Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "\n",
    "results['ICD9_CODE'] = df['ICD9_CODE'].apply(format_icd9)\n",
    "results['Recall'] = df.apply(lambda x: recall_score(x['L2_CODES'], x['Generated']), axis=1)\n",
    "results['Precision'] = df.apply(lambda x: precision_score(x['L2_CODES'], x['Generated']), axis=1)\n",
    "results['F1 Score'] = df.apply(lambda x: f1_score(x['L2_CODES'], x['Generated']), axis=1)\n",
    "display(results[['Recall', 'Precision', 'F1 Score']].mean(axis=0)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grade Final  ICD 9 Code Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "results['ICD9_CODE'] = df['ICD9_CODE'].apply(format_icd9)\n",
    "results['Recall'] = df.apply(lambda x: recall_score(x['ICD9_CODE'], x['Generated']), axis=1)\n",
    "results['Precision'] = df.apply(lambda x: precision_score(x['ICD9_CODE'], x['Generated']), axis=1)\n",
    "results['F1 Score'] = df.apply(lambda x: f1_score(x['ICD9_CODE'], x['Generated']), axis=1)\n",
    "\n",
    "display(results[['Recall', 'Precision', 'F1 Score']].mean(axis=0)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Recall = {round(results['Recall'].mean(),2)}\")\n",
    "print(f\"Precision = {round(results['Precision'].mean(),2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Med NLP Note Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "df['Parsed_Generated'] = \"\"\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    # Parse Note\n",
    "    note = row['PARSED_TEXT']\n",
    "    print(f\"Note: {note}\")\n",
    "\n",
    "    # Get Codes\n",
    "    result = flatten(get_codes_for_note(\"0\", code_tree, note, level=2)) # Change level here if needed\n",
    "\n",
    "    # Add result to DF\n",
    "    df.at[index, 'Parsed_Generated'] = str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df[['ICD9_CODE','L1_CODES','L2_CODES', 'Parsed_Generated']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "\n",
    "\n",
    "results['ICD9_CODE'] = df['ICD9_CODE'].apply(format_icd9)\n",
    "results['Recall'] = df.apply(lambda x: recall_score(x['L2_CODES'], x['Parsed_Generated']), axis=1)\n",
    "results['Precision'] = df.apply(lambda x: precision_score(x['L2_CODES'], x['Parsed_Generated']), axis=1)\n",
    "results['F1 Score'] = df.apply(lambda x: f1_score(x['L2_CODES'], x['Parsed_Generated']), axis=1)\n",
    "display(results[['Recall', 'Precision', 'F1 Score']].mean(axis=0)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
