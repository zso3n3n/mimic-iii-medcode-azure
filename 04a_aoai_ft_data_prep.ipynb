{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning for Medical Coding  \n",
    "#### Part 1: Data Preparation  \n",
    "\n",
    "---\n",
    "\n",
    "**Goal for this Notebook**\n",
    "- Prepare a dataset to fine tune a model for L1 (Chapter) level classification. The reason for fine-tuning at a 'higher' level is to eliminate challenges assocaited with the long-tail problem. This exercise will fine tune a model for multi-label classification with 17 label options.\n",
    "  \n",
    "<small>[_Click here for a complete list of ICD9 Chapters_](https://en.wikipedia.org/wiki/List_of_ICD-9_codes)</small>\n",
    "\n",
    "**Approach**\n",
    "  \n",
    "The dataset will be created using the ICD9 code tree to create descriptions for chapter classifications. For example, for a single chapter we can create many rows for training by using the ICD code name, child code names, and supplement information from UMLS.\n",
    "<small>\n",
    "```markdown\n",
    "--> Chapter name / description  \n",
    "    --> UMLS concept atoms  \n",
    "    --> UMLS concept definitions  \n",
    "    --> Children, grandchildren, etc node names / descriptions  \n",
    "        --> UMLS concept atoms  \n",
    "        --> UMLS concept definitions  \n",
    "```\n",
    "</small>  \n",
    "\n",
    "**Data**\n",
    "\n",
    "The dataset will need to be formatted in json format as follows:\n",
    "<small>\n",
    "```json\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"<SYSTEM MSG>\"}, {\"role\": \"user\", \"content\": \"<PROMPT>\"}, {\"role\": \"assistant\", \"content\": \"<CODE>\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"<SYSTEM MSG>\"}, {\"role\": \"user\", \"content\": \"<PROMPT>\"}, {\"role\": \"assistant\", \"content\": \"<CODE>\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"<SYSTEM MSG>\"}, {\"role\": \"user\", \"content\": \"<PROMPT>\"}, {\"role\": \"assistant\", \"content\": \"<CODE>\"}]}\n",
    "```\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from src.icd9_tree import ICD9\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from textwrap import dedent\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate to Client\n",
    "# Authenticate the client using your key and endpoint \n",
    "key = os.getenv(\"LANGUAGE_KEY\")\n",
    "endpoint = os.getenv(\"LANGUAGE_ENDPOINT\")\n",
    "\n",
    "ta_credential = AzureKeyCredential(key)\n",
    "client = TextAnalyticsClient(\n",
    "        endpoint=endpoint, \n",
    "        credential=ta_credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Setup Code Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ICD9 codes in as a tree and view top level. These 'Chapter' codes will be the labels for our fine tuned model.\n",
    "\n",
    "tree = ICD9('icd9_codes_full.json')\n",
    "chapter_codes = []\n",
    "# list of top level codes (e.g., '001-139', ...)\n",
    "toplevelnodes = tree.children\n",
    "for node in toplevelnodes:\n",
    "    if node.code[0] not in ['E', 'V']:\n",
    "        print(node.code, node.description)\n",
    "        chapter_codes.append(node.code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Establish Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the UMLS CUID(s) for a given text\n",
    "# This function uses Azure Text Analytics for Health\n",
    "\n",
    "def get_umls_concepts(client, documents):\n",
    "    umls_concepts = []\n",
    "    poller = client.begin_analyze_healthcare_entities(documents)\n",
    "    result = poller.result()\n",
    "\n",
    "    docs = [doc for doc in result if not doc.is_error]\n",
    "\n",
    "    for idx, doc in enumerate(docs):\n",
    "        for entity in doc.entities:\n",
    "            if entity.data_sources and entity.category in ['SymptonOrSign', 'Diagnosis']:\n",
    "                for data_source in entity.data_sources:\n",
    "                    if data_source.name == \"UMLS\":\n",
    "                        umls_concepts.append(data_source.entity_id)\n",
    "\n",
    "    return umls_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the UMLS atoms from a cuid\n",
    "\n",
    "def get_umls_atoms(cuid):\n",
    "    synonyms = []\n",
    "    sabs = ['ICD10', 'ICD10CM', 'ICD9CM', 'SNOMEDCT_US', 'MDR']      \n",
    "    atom_uri = f\"https://uts-ws.nlm.nih.gov/rest/content/2024AA/CUI/{cuid}/atoms\"\n",
    "    page = 0  \n",
    "    try:   \n",
    "        while True:\n",
    "            page += 1\n",
    "            atom_query = {'apiKey':os.getenv(\"UMLS_API_KEY\"), 'pageNumber':page, 'language':'ENG', 'sabs': ','.join(sabs)}\n",
    "            a = requests.get(atom_uri, params=atom_query)\n",
    "            a.encoding = 'utf-8'\n",
    "            \n",
    "            if a.status_code != 200:\n",
    "                break\n",
    "\n",
    "            all_atoms = a.json()\n",
    "        \n",
    "            for atom in all_atoms['result']:\n",
    "                synonyms.append(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", atom['name']).lower().rstrip())\n",
    "                #print(f'{atom}')\n",
    "\n",
    "            return list(set(synonyms))\n",
    "            \n",
    "    except Exception as except_error:\n",
    "        print(except_error)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get UMLS definition list from a cuid\n",
    "\n",
    "def umls_define(cuid):    \n",
    "    definitions = []\n",
    "    umls_uri = f\"https://uts-ws.nlm.nih.gov/rest/content/current/CUI/{cuid}/definitions\"\n",
    "    root_sources = ['CSP','NCI','MSH','PDQ', 'MTH', 'HPO', 'DXP', 'SNMI', 'SNOMEDCT_US', 'ICD10CM', 'ICD10', 'ICD9CM', 'MDR']  \n",
    "    page = 0  \n",
    "    try:   \n",
    "        while True:\n",
    "            page += 1\n",
    "            query = {'apiKey':os.getenv(\"UMLS_API_KEY\"), 'pageNumber':page}\n",
    "            a = requests.get(umls_uri, params=query)\n",
    "            a.encoding = 'utf-8'\n",
    "            \n",
    "            if a.status_code != 200:\n",
    "                break\n",
    "            result = a.json()\n",
    "        \n",
    "            for value in result['result']:\n",
    "                if value['rootSource'] in root_sources:\n",
    "                    definitions.append(value['value'].lower().rstrip())\n",
    "\n",
    "            return list(set(definitions))\n",
    "            \n",
    "    except Exception as except_error:\n",
    "        print(except_error)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the above functions to get json line for all atoms/definitions for a given ICD9 code\n",
    "\n",
    "def generate_dataset(sys, description, l1_code, az_ta_cli, training_file):\n",
    "    with open(training_file, \"a\") as file:\n",
    "\n",
    "        desc_data = {\"messages\":[ {\"role\": \"system\", \"content\": sys}, {\"role\": \"user\", \"content\": description}, {\"role\": \"assistant\", \"content\": l1_code} ] }\n",
    "        file.write(json.dumps(desc_data) + \"\\n\")\n",
    "\n",
    "        umls_concepts = get_umls_concepts(az_ta_cli, [description])\n",
    "        for cuid in umls_concepts:\n",
    "            \n",
    "            atoms = get_umls_atoms(cuid)\n",
    "            if atoms:\n",
    "                for atom in atoms:\n",
    "                    atom_data = {\"messages\":[ {\"role\": \"system\", \"content\": sys}, {\"role\": \"user\", \"content\": atom}, {\"role\": \"assistant\", \"content\": l1_code} ] }\n",
    "                    file.write(json.dumps(atom_data) + \"\\n\")\n",
    "\n",
    "            definitions = umls_define(cuid)\n",
    "            if definitions:\n",
    "                for definition in definitions:\n",
    "                    def_data = {\"messages\":[ {\"role\": \"system\", \"content\": sys}, {\"role\": \"user\", \"content\": definition}, {\"role\": \"assistant\", \"content\": l1_code} ] }\n",
    "                    file.write(json.dumps(def_data) + \"\\n\")\n",
    "\n",
    "    file.close()\n",
    "    return\n",
    "\n",
    "\n",
    "### Test ###\n",
    "# open('data/ft/training_data.jsonl', 'w').close()\n",
    "# generate_dataset(\"System\", \"Diabetes\", \"001-139\", client, \"data/ft/training_data.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Create Fine Tuning Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system prompt will be a constant in all examples\n",
    "\n",
    "sys = 'Classify the following text into an ICD9 code chapter. The text is a clinical note from a patient medical record. ### You must choose from the following semi-colon delimited list of codes:{0} ### RESPOND ONLY WITH A CODE FROM THE LIST ABOVE.'.format('; '.join(chapter_codes))\n",
    "print(dedent(sys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset - woohoo! \n",
    "# (NOTE: This may take a while)\n",
    "# TODO: Make this more efficient\n",
    "\n",
    "output_file = \"data/ft/training_data.jsonl\"\n",
    "open(output_file, 'w').close()\n",
    "\n",
    "for L1_node in tree.children:\n",
    "    if L1_node.code[0] not in ['E', 'V']:\n",
    "        # Get all json lines at the L1 level\n",
    "        # print(f\"L1: {L1_node.code} - {L1_node.description}\")\n",
    "        generate_dataset(sys, L1_node.description, L1_node.code, client, output_file)\n",
    "        for L2_node in L1_node.children:\n",
    "            # print(f\"L2: {L2_node.code} - {L2_node.description}\")\n",
    "            generate_dataset(sys, L2_node.description, L1_node.code, client, output_file)\n",
    "            for L3_node in L2_node.children:\n",
    "                # print(f\"L3: {L3_node.code} - {L3_node.description}\")\n",
    "                generate_dataset(sys, L3_node.description, L1_node.code, client, output_file)\n",
    "                for L4_node in L3_node.children:\n",
    "                    # print(f\"L4: {L4_node.code} - {L4_node.description}\")\n",
    "                    # generate_dataset(sys, L4_node.description, L1_node.code, client, output_file)\n",
    "                    for L5_node in L4_node.children:\n",
    "                        # print(f\"L5: {L5_node.code} - {L5_node.description}\")\n",
    "                        # generate_dataset(sys, L5_node.description, L1_node.code, client, output_file)\n",
    "                        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Examine the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(output_file, lines=True)\n",
    "display(df.head(2))\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long tail problem no more\n",
    "\n",
    "df['code'] = df['messages'].apply(lambda x: x[2]['content'])\n",
    "print(df['code'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
