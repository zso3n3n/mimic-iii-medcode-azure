{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning for Medical Coding  \n",
    "#### Part 1: Data Preparation  \n",
    "\n",
    "---\n",
    "\n",
    "**Goal for this Notebook**\n",
    "- Prepare a dataset to fine tune a model for L1 (Chapter) level classification. The reason for fine-tuning at a 'higher' level is to eliminate challenges assocaited with the long-tail problem. This exercise will fine tune a model for multi-label classification with 17 label options.\n",
    "  \n",
    "<small>[_Click here for a complete list of ICD9 Chapters_](https://en.wikipedia.org/wiki/List_of_ICD-9_codes)</small>\n",
    "\n",
    "**Approach**\n",
    "  \n",
    "The dataset will be created using the ICD9 code tree to create descriptions for chapter classifications. For example, for a single chapter we can create many rows for training by using the ICD code name, child code names, and supplement information from UMLS.\n",
    "<small>\n",
    "```markdown\n",
    "--> Chapter name / description  \n",
    "    --> UMLS concept atoms  \n",
    "    --> UMLS concept definitions  \n",
    "    --> Children, grandchildren, etc node names / descriptions  \n",
    "        --> UMLS concept atoms  \n",
    "        --> UMLS concept definitions  \n",
    "```\n",
    "</small>  \n",
    "\n",
    "**Data**\n",
    "\n",
    "The dataset will need to be formatted in json format as follows:\n",
    "<small>\n",
    "```json\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"<SYSTEM MSG>\"}, {\"role\": \"user\", \"content\": \"<PROMPT>\"}, {\"role\": \"assistant\", \"content\": \"<CODE>\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"<SYSTEM MSG>\"}, {\"role\": \"user\", \"content\": \"<PROMPT>\"}, {\"role\": \"assistant\", \"content\": \"<CODE>\"}]}\n",
    "{\"messages\": [{\"role\": \"system\", \"content\": \"<SYSTEM MSG>\"}, {\"role\": \"user\", \"content\": \"<PROMPT>\"}, {\"role\": \"assistant\", \"content\": \"<CODE>\"}]}\n",
    "```\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from src.icd9_tree import ICD9\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from textwrap import dedent\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate to Client\n",
    "# Authenticate the client using your key and endpoint \n",
    "key = os.getenv(\"LANGUAGE_KEY\")\n",
    "endpoint = os.getenv(\"LANGUAGE_ENDPOINT\")\n",
    "\n",
    "ta_credential = AzureKeyCredential(key)\n",
    "client = TextAnalyticsClient(\n",
    "        endpoint=endpoint, \n",
    "        credential=ta_credential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Setup Code Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ICD9 codes in as a tree and view top level. These 'Chapter' codes will be the labels for our fine tuned model.\n",
    "\n",
    "tree = ICD9('icd9_codes_full.json')\n",
    "chapter_codes = []\n",
    "# list of top level codes (e.g., '001-139', ...)\n",
    "toplevelnodes = tree.children\n",
    "for node in toplevelnodes:\n",
    "    if node.code[0] not in ['E', 'V']:\n",
    "        print(node.code, node.description)\n",
    "        chapter_codes.append(node.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Establish Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get code from description\n",
    "def get_chapter_code(description):\n",
    "    code = None\n",
    "    for node in tree.children:\n",
    "        if node.description.strip() == description.strip():\n",
    "            code = node.code\n",
    "            break\n",
    "        else:\n",
    "            for child in node.children:\n",
    "                if child.description.strip() == description.strip():\n",
    "                    code = child.code\n",
    "                    break\n",
    "    return code\n",
    "\n",
    "print(get_chapter_code('COMPLICATIONS OF PREGNANCY, CHILDBIRTH, AND THE PUERPERIUM'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the UMLS CUID(s) for a given text\n",
    "# This function uses Azure Text Analytics for Health\n",
    "\n",
    "def get_umls_concepts(client, documents):\n",
    "    umls_concepts = []\n",
    "    poller = client.begin_analyze_healthcare_entities(documents)\n",
    "    result = poller.result()\n",
    "\n",
    "    docs = [doc for doc in result if not doc.is_error]\n",
    "\n",
    "    for idx, doc in enumerate(docs):\n",
    "        for entity in doc.entities:\n",
    "            if entity.data_sources and entity.category in ['SymptonOrSign', 'Diagnosis']:\n",
    "                for data_source in entity.data_sources:\n",
    "                    if data_source.name == \"UMLS\":\n",
    "                        umls_concepts.append(data_source.entity_id)\n",
    "\n",
    "    return umls_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the UMLS atoms from a cuid\n",
    "\n",
    "def get_umls_atoms(cuid):\n",
    "    synonyms = []\n",
    "    sabs = ['ICD10', 'ICD10CM', 'ICD9CM', 'SNOMEDCT_US', 'MDR']      \n",
    "    atom_uri = f\"https://uts-ws.nlm.nih.gov/rest/content/2024AA/CUI/{cuid}/atoms\"\n",
    "    page = 0  \n",
    "    try:   \n",
    "        while True:\n",
    "            page += 1\n",
    "            atom_query = {'apiKey':os.getenv(\"UMLS_API_KEY\"), 'pageNumber':page, 'language':'ENG', 'sabs': ','.join(sabs)}\n",
    "            a = requests.get(atom_uri, params=atom_query)\n",
    "            a.encoding = 'utf-8'\n",
    "            \n",
    "            if a.status_code != 200:\n",
    "                break\n",
    "\n",
    "            all_atoms = a.json()\n",
    "        \n",
    "            for atom in all_atoms['result']:\n",
    "                synonyms.append(re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", atom['name']).lower().rstrip())\n",
    "                #print(f'{atom}')\n",
    "\n",
    "            return list(set(synonyms))\n",
    "            \n",
    "    except Exception as except_error:\n",
    "        print(except_error)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get UMLS definition list from a cuid\n",
    "\n",
    "def umls_define(cuid):    \n",
    "    definitions = []\n",
    "    umls_uri = f\"https://uts-ws.nlm.nih.gov/rest/content/current/CUI/{cuid}/definitions\"\n",
    "    root_sources = ['CSP','NCI','MSH','PDQ', 'MTH', 'HPO', 'DXP', 'SNMI', 'SNOMEDCT_US', 'ICD10CM', 'ICD10', 'ICD9CM', 'MDR']  \n",
    "    page = 0  \n",
    "    try:   \n",
    "        while True:\n",
    "            page += 1\n",
    "            query = {'apiKey':os.getenv(\"UMLS_API_KEY\"), 'pageNumber':page}\n",
    "            a = requests.get(umls_uri, params=query)\n",
    "            a.encoding = 'utf-8'\n",
    "            \n",
    "            if a.status_code != 200:\n",
    "                break\n",
    "            result = a.json()\n",
    "        \n",
    "            for value in result['result']:\n",
    "                if value['rootSource'] in root_sources:\n",
    "                    definitions.append(value['value'].lower().rstrip())\n",
    "\n",
    "            return list(set(definitions))\n",
    "            \n",
    "    except Exception as except_error:\n",
    "        print(except_error)\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate pd dataset\n",
    "\n",
    "def generate_dataset(description, chapter, az_ta_cli, dataset_list):\n",
    "    dataset_list.append({'description': description, 'chapter': chapter})\n",
    "\n",
    "    umls_concepts = get_umls_concepts(az_ta_cli, [description])\n",
    "    for cuid in umls_concepts:\n",
    "        \n",
    "        atoms = get_umls_atoms(cuid)\n",
    "        if atoms:\n",
    "            for atom in atoms:\n",
    "                dataset_list.append({'description': atom, 'chapter': chapter})\n",
    "\n",
    "        definitions = umls_define(cuid)\n",
    "        if definitions:\n",
    "            for definition in definitions:\n",
    "                dataset_list.append({'description': definition, 'chapter': chapter})\n",
    "    return\n",
    "\n",
    "# Test\n",
    "test_list = []\n",
    "generate_dataset('COMPLICATIONS OF PREGNANCY, CHILDBIRTH, AND THE PUERPERIUM', '001-139', client, test_list)\n",
    "print(test_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Create Fine Tuning Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the dataset \n",
    "# NOTE: This may take a while (15 min per 1500 samples)\n",
    "# TODO: Make this more efficient\n",
    "\n",
    "ft_df_list = []\n",
    "\n",
    "for L1_node in tree.children:\n",
    "    if L1_node.code[0] not in ['E', 'V']:\n",
    "        # print(f\"L1: {L1_node.code} - {L1_node.description}\")\n",
    "        generate_dataset(L1_node.description, L1_node.description, client, ft_df_list)\n",
    "        for L2_node in L1_node.children:\n",
    "            # print(f\"L2: {L2_node.code} - {L2_node.description}\")\n",
    "            generate_dataset(L2_node.description, L1_node.description, client, ft_df_list)\n",
    "            for L3_node in L2_node.children:\n",
    "                # print(f\"L3: {L3_node.code} - {L3_node.description}\")\n",
    "                generate_dataset(L3_node.description, L1_node.description, client, ft_df_list)\n",
    "                for L4_node in L3_node.children:\n",
    "                    # print(f\"L4: {L4_node.code} - {L4_node.description}\")\n",
    "                    # generate_dataset(L4_node.description, L1_node.description, client, ft_df_list)\n",
    "                    for L5_node in L4_node.children:\n",
    "                        # print(f\"L5: {L5_node.code} - {L5_node.description}\")\n",
    "                        # generate_dataset(L5_node.description, L1_node.description, client, ft_df_list)\n",
    "                        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load to dataframe and examine data\n",
    "ft_df = pd.DataFrame(ft_df_list)\n",
    "ft_df.chapter = ft_df.chapter.apply(lambda x: x.strip())\n",
    "print(ft_df.shape)\n",
    "print(ft_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add multi-label examples to the dataframe (normal distribution with a mean of 6 labels per example [min 1, max 12])\n",
    "\n",
    "def multi_sample(code_count, sample_count):\n",
    "    new_rows = []\n",
    "    for i in range(sample_count):\n",
    "        code_samples = list(map(str.strip, random.sample(chapter_codes, code_count)))\n",
    "        item = {'description': '', 'chapter': ';'.join(code_samples)}\n",
    "        desciption_list = []\n",
    "        for chapter in code_samples:\n",
    "            sample = ft_df[ft_df['chapter']==chapter].sample(1)\n",
    "            desciption_list.append(sample['description'].values[0])\n",
    "\n",
    "        item['description'] = ','.join(desciption_list)   \n",
    "        new_rows.append(item)\n",
    "    return new_rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add multi-label examples to the dataframe\n",
    "# TODO: Add data according to the distribution of the MIMIC-III dataset; this is a rough estimate\n",
    "\n",
    "sample_multiplier = 100\n",
    "\n",
    "ft_df = pd.concat([ft_df, pd.DataFrame(multi_sample(2,1*sample_multiplier))], ignore_index=True)\n",
    "ft_df = pd.concat([ft_df, pd.DataFrame(multi_sample(3,2*sample_multiplier))], ignore_index=True)\n",
    "ft_df = pd.concat([ft_df, pd.DataFrame(multi_sample(4,3*sample_multiplier))], ignore_index=True)\n",
    "ft_df = pd.concat([ft_df, pd.DataFrame(multi_sample(5,5*sample_multiplier))], ignore_index=True)\n",
    "ft_df = pd.concat([ft_df, pd.DataFrame(multi_sample(6,10*sample_multiplier))], ignore_index=True)\n",
    "ft_df = pd.concat([ft_df, pd.DataFrame(multi_sample(7,6*sample_multiplier))], ignore_index=True)\n",
    "ft_df = pd.concat([ft_df, pd.DataFrame(multi_sample(8,5*sample_multiplier))], ignore_index=True)\n",
    "ft_df = pd.concat([ft_df, pd.DataFrame(multi_sample(9,4*sample_multiplier))], ignore_index=True)\n",
    "ft_df = pd.concat([ft_df, pd.DataFrame(multi_sample(10,3*sample_multiplier))], ignore_index=True)\n",
    "ft_df = pd.concat([ft_df, pd.DataFrame(multi_sample(11,2*sample_multiplier))], ignore_index=True)\n",
    "ft_df = pd.concat([ft_df, pd.DataFrame(multi_sample(12,1*sample_multiplier))], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ft_df.shape)\n",
    "display(ft_df.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define system prompt\n",
    "# system prompt will be a constant in all examples\n",
    "sys = 'Classify the following text into an ICD9 code chapter. The text is a clinical note from a patient medical record. ### You must choose from the following semi-colon delimited list of codes:{0} ### RESPOND ONLY WITH A CODE FROM THE LIST ABOVE.'.format('; '.join(chapter_codes))\n",
    "print(dedent(sys))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply formatting to each row\n",
    "ft_df[\"chapter\"] = ft_df.chapter.apply(lambda x: {\"role\": \"assistant\", \"content\": x})\n",
    "ft_df[\"description\"] = ft_df.description.apply(lambda x: {\"role\": \"user\", \"content\": x})\n",
    "ft_df['sys'] = sys\n",
    "ft_df[\"sys\"] = ft_df.sys.apply(lambda x: {\"role\": \"system\", \"content\": x})\n",
    "ft_df = ft_df.reindex(columns=['sys', 'description', 'chapter'])\n",
    "\n",
    "out_df = pd.DataFrame()\n",
    "out_df = ft_df.apply(lambda x: {\"messages\": x.values}, axis=1)\n",
    "\n",
    "display(out_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file\n",
    "output_file_name = \"data/ft/training_data_L1toL3_multi.jsonl\"\n",
    "out_df.to_json(output_file_name, orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Examine the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(output_file_name, lines=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm value counts\n",
    "df['code'] = df['messages'].apply(lambda x: x[1]['content'])\n",
    "print(df['code'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
