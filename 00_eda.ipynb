{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mimic-III + ICD9 Data Analysis\n",
    "\n",
    "**Challenges with AI based Medical Coding**  \n",
    "  \n",
    "This notebook will explore/demonstrate the data based challenges that make AI based medical coding difficult:  \n",
    "- The Long Tail Problem\n",
    "- Vast label space\n",
    "- Medical Note Complexity\n",
    "\n",
    "**Dataset Details**  \n",
    "  \n",
    "Data for this analysis is from the semi-open [MIMIC-III Clinical Dataset](https://physionet.org/content/mimiciii/1.4/). **The data is not permenantly stored in this repository.** To access the data, follow the steps on the linked website and complete the necessary trainings. This data is for research purposes only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "from src.icd9_tree import ICD9\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Examine the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data/raw/\"\n",
    "d_icd = pd.read_csv(data_folder + 'D_ICD_DIAGNOSES.csv.gz', usecols=['ICD9_CODE', 'SHORT_TITLE', 'LONG_TITLE']) # ICD Code lookup\n",
    "diagnoses = pd.read_csv(data_folder + 'DIAGNOSES_ICD.csv.gz', usecols=['HADM_ID', 'ICD9_CODE']) # Linkage between ICD codes and Note events\n",
    "drg = pd.read_csv(data_folder + 'DRGCODES.csv.gz', usecols=['HADM_ID','DESCRIPTION']) # DRG Codes\n",
    "note_events= pd.read_csv(data_folder + 'NOTEEVENTS.csv.gz', usecols=['HADM_ID','TEXT'], nrows=20000) # Number of rows = 2,083,180 without filter # We will handle this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init Code Tree\n",
    "tree = ICD9('icd9_codes_full.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Sizes\n",
    "print(f\"D_ICD Shape: {d_icd.shape}\")\n",
    "print(f\"DIAGNOSES Shape: {diagnoses.shape}\")\n",
    "print(f\"DRG Shape: {drg.shape}\")\n",
    "print(f\"Note Events Shape: {note_events.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schemas\n",
    "print(f\"D_ICD Schema: {d_icd.columns}\")\n",
    "print(f\"DIAGNOSES Schema: {diagnoses.columns}\")\n",
    "print(f\"DRG Schema: {drg.columns}\")\n",
    "print(f\"Note Events Schema: {note_events.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primary tables for this exercise are the DIAGNOSES and NOTE_EVENTS tables\n",
    "# Joining these two tables will give us the linkage between the ICD codes and the notes\n",
    "\n",
    "note_events['TEXT'] = note_events['TEXT'].apply(lambda x: \"\\\"\" + str(x) + \"\\\"\")\n",
    "diagnoses = diagnoses.groupby(['HADM_ID']).agg(tuple).map(list).reset_index()\n",
    "joined = note_events.join(diagnoses.set_index(\"HADM_ID\"), on=['HADM_ID'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(joined.columns)\n",
    "print(joined.shape)\n",
    "display(joined.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### The Long Tail Problem\n",
    "  \n",
    "As with any classification problem, having a heavily skewed distribution presents a challenge with supervised learning. The MIMIC-III dataset presents this challenge to the MAX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Distribution of codes from Diagnoses table\n",
    "def remove_evm_codes(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Drop E, V, and M codes\n",
    "    df['ICD9_CODE'] = df['ICD9_CODE'].apply(lambda x: str(x))\n",
    "    output = df[~df['ICD9_CODE'].str.startswith(\"E\")]\n",
    "    output = output[~output['ICD9_CODE'].str.startswith(\"V\")]   \n",
    "    output = output[~output['ICD9_CODE'].str.startswith(\"M\")]\n",
    "    return output\n",
    "\n",
    "# DIAGNOSES Schema: Index(['HADM_ID', 'ICD9_CODE'], dtype='object')\n",
    "diagnoses = pd.read_csv(data_folder + 'DIAGNOSES_ICD.csv.gz', usecols=['HADM_ID', 'ICD9_CODE']) \n",
    "df = diagnoses[diagnoses['ICD9_CODE'].notna()]\n",
    "df = df.drop(columns=['HADM_ID'])\n",
    "\n",
    "# Drop codes that start with E, V, and M\n",
    "df = remove_evm_codes(df)\n",
    "\n",
    "# Shorten codes to 3 digits (for now)\n",
    "df['ICD9_CODE'] = df['ICD9_CODE'].str.slice(0, 3)\n",
    "\n",
    "# Explode list\n",
    "df['ICD9_CODE'] = df['ICD9_CODE'].explode('ICD9_CODE').reset_index(drop=True)\n",
    "\n",
    "# Get count for each ecode\n",
    "df = df.value_counts().reset_index()\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ALL codes (for dramatic effect - this is not useful)\n",
    "\n",
    "fig = px.bar(df.nlargest(columns=['count'], n=df.shape[0]), x='ICD9_CODE', y='count',color='ICD9_CODE', title='Code Counts')\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the top 200 codes - the long tail still extists even after taking a subset!!!\n",
    "\n",
    "fig = px.bar(df.nlargest(columns=['count'], n=200), x='ICD9_CODE', y='count',color='ICD9_CODE', title='Code Counts')\n",
    "fig.update_layout(xaxis={'categoryorder':'total descending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The TOP X codes represent what percent of the MIMIC-III data?\n",
    "x=int(input(\"Enter a number: \"))\n",
    "\n",
    "top_100 = df.nlargest(columns=['count'], n=x)\n",
    "top_100_sum = top_100['count'].sum()\n",
    "total_sum = df['count'].sum()\n",
    "\n",
    "print(f\"Top {x} Codes represent {top_100_sum/total_sum*100:.2f}% of the data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Vast Label Space  \n",
    "  \n",
    "For this exercise we omit 'E' and 'V' codes - however we are still left with a humungous label space. The quantity of potential labels presents challenges with multi-label classification - there are a lot of different options a model can choose from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read ICD9 codes in as a tree and view top level (we will call them L1 or Chapters) codes\n",
    "# Note: L0 is the root node\n",
    "\n",
    "# list of top level codes (e.g., '001-139', ...)\n",
    "toplevelnodes = tree.children\n",
    "for node in toplevelnodes:\n",
    "    if node.code[0] not in ['E', 'V']:\n",
    "        print(node.code, node.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts of all code levels and plot results\n",
    "L1 = 0\n",
    "L2 = 0\n",
    "L3 = 0\n",
    "L4 = 0\n",
    "L5 = 0\n",
    "\n",
    "for node in tree.children:\n",
    "    if node.code[0] not in ['E', 'V']:\n",
    "        L1 += 1\n",
    "        L2 += len(node.children)\n",
    "        for l2_child in node.children:\n",
    "            L3 += len(l2_child.children)\n",
    "            for l3_child in l2_child.children:\n",
    "                L4 += len(l3_child.children)\n",
    "                for l4_child in l3_child.children:\n",
    "                    L5 += len(l4_child.children)\n",
    "\n",
    "print(f\"Counts:\\nL1: {L1}\\nL2: {L2}\\nL3: {L3}\\nL4: {L4}\\nL5: {L5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of codes at each level\n",
    "data = {'Level': ['L1', 'L2', 'L3', 'L4', 'L5'], 'Count': [L1, L2, L3, L4, L5]}\n",
    "df = pd.DataFrame(data)\n",
    "fig = px.bar(df, x='Level', y='Count', title='Code Counts by Level', color='Level')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Note Complexity  \n",
    "  \n",
    "Note complexity presents another challenge to the classification problem. Note Texts from the Mimic dataset are...\n",
    "- Poorly formatted\n",
    "- Difficult to contextualize - for example the use of specific medical acronyms or sitations where a patient does NOT have xyz condition/symptom\n",
    "- Lengthy (in terms of tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets look at a ramdon note text\n",
    "display(note_events.sample(1, random_state=123)[['TEXT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the average number of tokens in the notes\n",
    "\n",
    "def get_token_counts(text):\n",
    "    encoding = tiktoken.get_encoding('cl100k_base')\n",
    "    num_tokens = len(encoding.encode(text))\n",
    "    return num_tokens\n",
    "\n",
    "note_events['num_tokens'] = note_events['TEXT'].apply(get_token_counts)\n",
    "print(f\"Average Token Count: {note_events['num_tokens'].mean()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Plot L1 Code Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.find('191.1').parents[1].code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to get L1 codes\n",
    "def get_cat_code(code_list, level, tree):\n",
    "    chapter_code_list = []\n",
    "    error_list = []\n",
    "    for code in code_list:\n",
    "        try:\n",
    "            if code[0] not in ['E', 'V']:\n",
    "                if len(code) > 3:\n",
    "                    code = code[:3] + '.' + code[3:]\n",
    "                    chapter_code_list.append(tree.find(code).parents[level].code)\n",
    "        except:\n",
    "            if code not in error_list:\n",
    "                error_list.append(code)\n",
    "            \n",
    "    # print(f\"Error List: {error_list}\")\n",
    "    return list(set(chapter_code_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get L1 codes\n",
    "codes_df = joined.copy()\n",
    "codes_df['L1'] = codes_df['ICD9_CODE'].apply(lambda x: get_cat_code(x, 1, tree))\n",
    "display(codes_df[['L1', 'ICD9_CODE']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get L1_Len\n",
    "codes_df['L1_Len'] = codes_df['L1'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot L1_Len counts\n",
    "fig = px.bar(codes_df.value_counts('L1_Len').reset_index(), x='L1_Len', y='count', title='L1 Length Counts')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "med_code",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
